{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntSlider, interactive\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE = tf.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=np.load('./dataset/X_matrix.npy')\n",
    "Y=pd.read_pickle('./dataset/Y.p')\n",
    "Data_order=Y.index.values.astype(np.int16)\n",
    "Y_data=Y.PSI.values.astype(np.float32)\n",
    "Y_data[Y_data <= 0.10] = 0\n",
    "Y_data[Y_data >= 0.70] = 1\n",
    "data_selected = (Y_data == 0) + (Y_data == 1)\n",
    "x_data = X_data[data_selected]\n",
    "y_data = Y_data[data_selected]\n",
    "data_order = Data_order[data_selected]\n",
    "y_data=y_data.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_data[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(x):\n",
    "    plt.imshow(x_data[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive(display_image, x=IntSlider(min=0,max=x_data.shape[0]-1,step=1,value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    \n",
    "    Arguments:\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    encoding = np.eye(2)[x]\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data=one_hot_encode(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Shuffle and Split the Data into 4 Training Batches and 1 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_preprocess_training_batch(X, y, batch_size):\n",
    "    \"\"\"\n",
    "    Save the preprocess batch data and validation data\n",
    "    \n",
    "    Arguments:\n",
    "    : X : features data\n",
    "    : y : labels data\n",
    "    : batch_size: the size of training batches\n",
    "    \"\"\"\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "    \n",
    "    n_batches=int(X.shape[0]/batch_size)-1\n",
    "    validation_count = X.shape[0]-batch_size*n_batches\n",
    "    \n",
    "    for batch_i in range(0, n_batches):\n",
    "        features, labels = X[batch_i*batch_size : (batch_i+1)*batch_size], y[batch_i*batch_size : (batch_i+1)*batch_size]\n",
    "        print(features.shape)\n",
    "        # Prprocess and save a batch of training data\n",
    "        filename = './dataset/train_batch_' + str(batch_i+1) + '.p'\n",
    "        pickle.dump((features, labels), open(filename, 'wb'))\n",
    "        \n",
    "    # Use a portion of training batch for validation\n",
    "    valid_features, valid_labels = X[-validation_count:], y[-validation_count:]\n",
    "    print(valid_features.shape)\n",
    "    # Preprocess and Save all validation data\n",
    "    pickle.dump((valid_features, valid_labels), open('./dataset/validation.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump_preprocess_training_batch(x_data, y_data, 236)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Batches with Specific Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \n",
    "    Arguments:\n",
    "    : batch_id : the id of the batch\n",
    "    : batch_size : batch size\n",
    "    \n",
    "    Returns:\n",
    "    : the batch features and labels\n",
    "    \"\"\"\n",
    "    filename = './dataset/train_batch_' + str(batch_id) + '.p'\n",
    "    features, labels = pickle.load(open(filename, mode='rb'))\n",
    "\n",
    "    # Return the training data in batches of size <batch_size> or less\n",
    "    return batch_features_labels(features, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_features, valid_labels = pickle.load(open('./dataset/validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net_input(image_shape, n_classes):\n",
    "    \"\"\"\n",
    "    Grouping nodes into a single name scope in the computation graph.\n",
    "    \n",
    "    Arguments:\n",
    "    : image_shape: The shape of image\n",
    "    : n_classes: The number of classes\n",
    "    \n",
    "    Returns:\n",
    "    : x, y, keep_prob_1, keep_prob_2, learning_rate, is_training\n",
    "    \"\"\"\n",
    "    with tf.name_scope('inputs'):\n",
    "        x = tf.placeholder(DTYPE, [None] + list(image_shape), name='x')\n",
    "        y = tf.placeholder(DTYPE, [None ,n_classes], name='y')\n",
    "        keep_prob_1 = tf.placeholder(DTYPE, None, name=\"keep_prob_1\")\n",
    "        keep_prob_2 = tf.placeholder(DTYPE, None, name=\"keep_prob_2\")\n",
    "        learning_rate = tf.placeholder(DTYPE, None, \"lr\")\n",
    "        is_training=tf.placeholder(tf.bool, None, name='is_training')\n",
    "    return x, y, keep_prob_1, keep_prob_2, learning_rate, is_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d(x_tensor, conv_num_outputs, conv_ksize, conv_strides, is_training, padding = 'SAME', l2_regularize=True, wd=0.0001):\n",
    "    \"\"\"\n",
    "    Apply 1D convolution to x_tensor\n",
    "    \n",
    "    Arguments:\n",
    "    : x_tensor: TensorFlow Tensor\n",
    "    : conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    : conv_ksize: Kernal size for the convolutional layer\n",
    "    : conv_strides: Stride for convolution\n",
    "    : is_training: Placeholder bool that hold the flag to determine training is True or False\n",
    "    : l2_regularize: Flag for l2 regularization\n",
    "    : wd: Weight decay\n",
    "    \n",
    "    Returns:\n",
    "    : A tensor that represents convolution of x_tensor\n",
    "    \"\"\"\n",
    "    X_shape = x_tensor.get_shape().as_list()\n",
    "    #print(X_shape)\n",
    "    C_kshape = list((conv_ksize,) + (X_shape[-1],) + (conv_num_outputs,))\n",
    "    #print(C_kshape)\n",
    "    \n",
    "    # The shape of the filter weight is (depth, height, width, input_channels, output_channels)\n",
    "    # The shape of the filter bias is (output_channels,)\n",
    "    F_W = tf.get_variable('W', shape=C_kshape, initializer=tf.contrib.layers.xavier_initializer(), dtype=DTYPE)\n",
    "    #F_b = tf.get_variable('b', shape=(conv_num_outputs,) , initializer=tf.constant_initializer(0.1, dtype=DTYPE))\n",
    "    #print(F_W.shape)\n",
    "    #print(F_b.shape)\n",
    "    if l2_regularize==True:\n",
    "        #wd = 0.0001\n",
    "        weight_decay = tf.multiply(tf.nn.l2_loss(F_W), wd, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "    \n",
    "    # The shape of the convolution stride is (batch_size, depth, height, width, channels)\n",
    "    C_strides = conv_strides\n",
    "    \n",
    "    # The padding, either 'VALID' or 'SAME'.\n",
    "    #padding = 'SAME'\n",
    "    conv_output = tf.nn.conv1d(x_tensor, F_W, C_strides, padding)\n",
    "    conv_output = tf.layers.batch_normalization(inputs=conv_output, training=is_training)\n",
    "    conv_output = tf.nn.elu(conv_output)\n",
    "    # Keeping track of weights and biases\n",
    "    tf.summary.histogram('weights', F_W)\n",
    "    #tf.summary.histogram('biases', F_b)\n",
    "    \n",
    "    return conv_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Maxpooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling1d(x_tensor, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply 1D pooling to x_tensor\n",
    "    \n",
    "    Arguments:\n",
    "    : x_tensor: TensorFlow Tensor\n",
    "    : pool_ksize: Kernal size for pool\n",
    "    : pool_strides: Stride for pool\n",
    "    \n",
    "    Returns:\n",
    "    : A tensor that represents max pooling of x_tensor\n",
    "    \"\"\"\n",
    "   # The padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'SAME'\n",
    "    P_kshape = pool_ksize\n",
    "    P_stride = pool_strides\n",
    "    \n",
    "    pooling_output = tf.layers.max_pooling1d(x_tensor,P_kshape,P_stride,padding)\n",
    "    \n",
    "    return pooling_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Size)\n",
    "    \n",
    "    Arguments:\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the 2D dimensions\n",
    "    \n",
    "    Returns:\n",
    "    : A tensor of size (Batch Size, Flattened Size)\n",
    "    \"\"\"\n",
    "    # reference : https://github.com/tensorflow/tensorflow/issues/7253\n",
    "    X_shape = x_tensor.get_shape().as_list()\n",
    "    \n",
    "    return tf.reshape(x_tensor,[-1,np.prod(X_shape[1:])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully-Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_conn(x_tensor, num_outputs, is_training, l2_regularize=True, wd=0.0001):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    \n",
    "    Arguments:\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size\n",
    "    : num_outputs: The number of output that the new tensor should be\n",
    "    : is_training: Placeholder bool that hold the flag to determine training is True or False\n",
    "    : l2_regularize: Flag for l2 regularization\n",
    "    \n",
    "    Returns:\n",
    "    : A 2-D tensor where the second dimension is num_outputs\n",
    "    \"\"\"\n",
    "    X_shape = x_tensor.get_shape().as_list()\n",
    "    shape = list((X_shape[-1],)+(num_outputs,))\n",
    "    \n",
    "    \n",
    "    W = tf.get_variable('W', shape=shape, initializer=tf.contrib.layers.xavier_initializer(),dtype=DTYPE)\n",
    "    #b = tf.get_variable('b', shape=(num_outputs,) , initializer=tf.constant_initializer(0.1, dtype=DTYPE))\n",
    "    \n",
    "    if l2_regularize==True:\n",
    "        #wd = 0.0001\n",
    "        weight_decay = tf.multiply(tf.nn.l2_loss(W), wd, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "    \n",
    "    fc_output = tf.matmul(x_tensor, W)\n",
    "    fc_output = tf.layers.batch_normalization(inputs=fc_output, training=is_training)\n",
    "    fc_output = tf.nn.elu(fc_output)\n",
    "    \n",
    "    # Keeping track of weights and biases\n",
    "    tf.summary.histogram('weights', W)\n",
    "    #tf.summary.histogram('biases', b)\n",
    "    \n",
    "    return fc_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    \n",
    "    Arguments:\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    \n",
    "    Returns:\n",
    "    : A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    X_shape = x_tensor.get_shape().as_list()\n",
    "    shape = list((X_shape[-1],)+(num_outputs,))\n",
    "    W = tf.get_variable('W', shape=shape, initializer=tf.contrib.layers.xavier_initializer(),dtype=DTYPE)\n",
    "    #b = tf.get_variable('b', shape=(num_outputs,) , initializer=tf.constant_initializer(0.1, dtype=DTYPE))\n",
    "    # Keeping track of weights and biases\n",
    "    tf.summary.histogram('weights', W)\n",
    "    #tf.summary.histogram('biases', b)\n",
    "    return tf.matmul(x_tensor, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global-Average-Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_avg_pooling(x_tensor):\n",
    "    \"\"\"\n",
    "    Apply a Global-Average-Pooling Layer to x_tensor\n",
    "    \n",
    "    Arguments:\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size\n",
    "    \n",
    "    Returns:\n",
    "    : A 2-D tensor where the second dimension is num_outputs\n",
    "    \"\"\"\n",
    "    X_shape = x_tensor.get_shape().as_list()\n",
    "    pool_size = X_shape[1]\n",
    "    output = tf.layers.average_pooling1d(inputs=x_tensor, pool_size=pool_size, strides=1)\n",
    "    output_shape = output.get_shape().as_list()\n",
    "    \n",
    "    return tf.reshape(output,[-1,np.prod(output_shape[1:])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Zero Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padding1d(x_tensor, pad):\n",
    "    \"\"\"\n",
    "    Apply 1D zero padding to x_tensor\n",
    "    \n",
    "    Arguments:\n",
    "    : x_tenor: TensorFlow Tensor\n",
    "    : pad: The pad size\n",
    "    \n",
    "    Returns:\n",
    "    : A tensor that represents zero padding of x_tensor\n",
    "    \"\"\"\n",
    "    paddings = tf.constant([[0,0], [pad, pad], [0,0]])\n",
    "    zero_padding_output = tf.pad(x_tensor, paddings, mode='CONSTANT', constant_values=0)\n",
    "    return zero_padding_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *THE Following are the Blocks used in ResNet Architecture. But I don't ues ResNet finally*\n",
    "\n",
    "If they are used, please comment out the two lines:\n",
    "\n",
    "\"conv_output = tf.layers.batch_normalization(inputs=conv_output, training=is_training)\" and \"conv_output = tf.nn.elu(conv_output)\" in conv1d function,\n",
    "\n",
    "and take off the \"is_training\" parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block, is_training, l2_regularize=True, wd=0.0001):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block\n",
    "    \n",
    "    Arguments:\n",
    "    : X: Input tensor of shape (m, n_S_prev, n_C_prev)\n",
    "    : f: Integer, specifying the shape of the middle CONV's window for the main path\n",
    "    : filters: Python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    : stage: Integer, used to name the layers, depending on their position in the network\n",
    "    : block: String/character, used to name the layers, depending on their position in the network\n",
    "    : is_training: Placeholder bool that hold the flag to determine training is True or False\n",
    "    \n",
    "    Returns:\n",
    "    : Output of the identity block, tensor of shape (m, n_S, n_C)\n",
    "    \"\"\"\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    with tf.variable_scope(conv_name_base + '2a'):\n",
    "        X = conv1d(X, conv_num_outputs=F1, conv_ksize=1, conv_strides=1, padding ='VALID', l2_regularize=l2_regularize, wd=wd)\n",
    "    with tf.variable_scope(bn_name_base + '2a'):\n",
    "        X = tf.layers.batch_normalization(X, training=is_training)\n",
    "    X = tf.nn.elu(X)\n",
    "    \n",
    "    # Second component of main path\n",
    "    with tf.variable_scope(conv_name_base + '2b'):\n",
    "        X = conv1d(X, conv_num_outputs=F2, conv_ksize=f, conv_strides=1, padding ='SAME', l2_regularize=l2_regularize, wd=wd)\n",
    "    with tf.variable_scope(bn_name_base + '2b'):\n",
    "        X = tf.layers.batch_normalization(X, training=is_training)\n",
    "    X = tf.nn.elu(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    with tf.variable_scope(conv_name_base + '2c'):\n",
    "        X = conv1d(X, conv_num_outputs=F3, conv_ksize=1, conv_strides=1, padding ='VALID', l2_regularize=l2_regularize, wd=wd)\n",
    "    with tf.variable_scope(bn_name_base + '2c'):\n",
    "        X = tf.layers.batch_normalization(X, training=is_training)\n",
    "    \n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    #X = X + X_shortcut\n",
    "    X = tf.add(X, X_shortcut)\n",
    "    X = tf.nn.elu(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s , is_training, l2_regularize=True, wd=0.0001):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block\n",
    "    \n",
    "    Arguments:\n",
    "    : X: Input tensor of shape (m, n_S_prev, n_C_prev)\n",
    "    : f: Integer, specifying the shape of the middle CONV's window for the main path\n",
    "    : filters: Python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    : stage: Integer, used to name the layers, depending on their position in the network\n",
    "    : block: String/character, used to name the layers, depending on their position in the network\n",
    "    : is_training: Boolean flag for BN\n",
    "    : s: Integer, specifying the stride to be used\n",
    "    : is_training: Placeholder bool that hold the flag to determine training is True or False\\\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    : output of the convolutional block, tensor of shape (m, n_S, n_C)\n",
    "    \"\"\"\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path\n",
    "    with tf.variable_scope(conv_name_base + '2a'):\n",
    "        X = conv1d(X, conv_num_outputs=F1, conv_ksize=1, conv_strides=s, padding ='VALID', l2_regularize=l2_regularize, wd=wd)\n",
    "    with tf.variable_scope(bn_name_base + '2a'):\n",
    "        X = tf.layers.batch_normalization(X, training=is_training)\n",
    "    X = tf.nn.elu(X)\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    with tf.variable_scope(conv_name_base + '2b'):\n",
    "        X = conv1d(X, conv_num_outputs=F2, conv_ksize=f, conv_strides=1, padding ='SAME', l2_regularize=l2_regularize, wd=wd)\n",
    "    with tf.variable_scope(bn_name_base + '2b'):\n",
    "        X = tf.layers.batch_normalization(X, training=is_training)\n",
    "    X = tf.nn.elu(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    with tf.variable_scope(conv_name_base + '2c'):\n",
    "        X = conv1d(X, conv_num_outputs=F3, conv_ksize=1, conv_strides=1, padding ='VALID', l2_regularize=l2_regularize, wd=wd)\n",
    "    with tf.variable_scope(bn_name_base + '2c'):\n",
    "        X = tf.layers.batch_normalization(X, training=is_training)\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    with tf.variable_scope(conv_name_base + '1'):\n",
    "        X_shortcut = conv1d(X_shortcut, conv_num_outputs=F3, conv_ksize=1, conv_strides=s, padding ='VALID', l2_regularize=l2_regularize, wd=wd)\n",
    "    with tf.variable_scope(bn_name_base + '1'):\n",
    "        X_shortcut = tf.layers.batch_normalization(X_shortcut, training=is_training)\n",
    "    \n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = tf.add(X, X_shortcut)\n",
    "    X = tf.nn.elu(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeepTf(X, keep_prob_1, keep_prob_2, is_training=False):\n",
    "    \"\"\"\n",
    "    Create a convolutional/dense neural network model\n",
    "    \n",
    "    Arguments:\n",
    "    : x: Placeholder tensor that holds data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : is_training: Placeholder bool that hold the flag to determine training is True or False, default is False\n",
    "    \n",
    "    Returns:\n",
    "    : Tensor that represents logits\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    with tf.name_scope(\"DNN\"):\n",
    "        \n",
    "        X = flatten(X)\n",
    "        \n",
    "        with tf.variable_scope('fc1'):\n",
    "            X = fully_conn(X, num_outputs=128, is_training= is_training, l2_regularize=True, wd=0.01)\n",
    "            X = tf.nn.dropout(X, keep_prob_1)\n",
    "        with tf.variable_scope('fc2'):\n",
    "            X = fully_conn(X, num_outputs=256, is_training = is_training, l2_regularize=True, wd=0.01)\n",
    "            X = tf.nn.dropout(X, keep_prob_1)\n",
    "        with tf.variable_scope('fc3'):\n",
    "            X = fully_conn(X, num_outputs=512, is_training = is_training, l2_regularize=True, wd=0.01)\n",
    "            X = tf.nn.dropout(X, keep_prob_2)\n",
    "        with tf.variable_scope('fc4'):\n",
    "            X = fully_conn(X, num_outputs=1024, is_training = is_training, l2_regularize=True, wd=0.01)\n",
    "            X = tf.nn.dropout(X, keep_prob_2)\n",
    "            \n",
    "        X = output(X, 2)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.name_scope(\"CNN\"):\n",
    "    \n",
    "        with tf.variable_scope('conv1'):\n",
    "            X = conv1d(X, conv_num_outputs=128, conv_ksize=7, conv_strides=1, is_training=is_training, padding = 'SAME', l2_regularize=True, wd=0.001)\n",
    "            X = max_pooling1d(X, pool_ksize=3, pool_strides=1)\n",
    "            X = tf.nn.dropout(X, keep_prob_2)\n",
    "\n",
    "        X = flatten(X)\n",
    "        \n",
    "        with tf.variable_scope('fc1'):\n",
    "            X = fully_conn(X, num_outputs=128, is_training= is_training, l2_regularize=True, wd=0.001)\n",
    "            X = tf.nn.dropout(X, keep_prob_2)\n",
    "        with tf.variable_scope('fc2'):\n",
    "            X = fully_conn(X, num_outputs=256, is_training = is_training, l2_regularize=True, wd=0.001)\n",
    "            X = tf.nn.dropout(X, keep_prob_2)\n",
    "            \n",
    "        X = output(X, 2)\n",
    "    \"\"\"\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a training op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_op():\n",
    "    # Remove previous weights, bias, inputs, etc..\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # Inputs\n",
    "    x, y, keep_prob_1, keep_prob_2, lr, is_training = neural_net_input((307, 2500), 2)\n",
    "    # Model\n",
    "    logits = DeepTf(x, keep_prob_1, keep_prob_2, is_training)\n",
    "    \n",
    "    global_step = tf.Variable(0)\n",
    "    \n",
    "    # Name logits Tensor, so that is can be loaded from disk after training\n",
    "    with tf.name_scope('logits'):\n",
    "        logits = tf.identity(logits, name='logits')\n",
    "\n",
    "    # Loss and Optimizer\n",
    "    with tf.name_scope('cost'):\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y), name='cost')\n",
    "        tf.add_to_collection('losses', cost)\n",
    "        cost_with_l2 = tf.add_n(tf.get_collection('losses'), name='cost_with_l2')\n",
    "    \n",
    "    loss_summ = tf.summary.scalar('loss_with_l2', cost_with_l2)\n",
    "    loss_summ = tf.summary.scalar('loss', cost)\n",
    "\n",
    "    \n",
    "    #with tf.name_scope('cost'):\n",
    "    #    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y), name='cost')\n",
    "    #loss_summ = tf.summary.scalar('loss', cost)\n",
    "    \n",
    "    with tf.name_scope('train'):\n",
    "        \n",
    "        # batch normalization in tensorflow requires this update dependency\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost_with_l2, global_step=global_step)\n",
    "    \n",
    "    #tf.add_to_collection('cost_op', cost)\n",
    "    #tf.add_to_collection('train_op', optimizer)\n",
    "    \n",
    "    # Accuracy\n",
    "    with tf.name_scope('predictions'):\n",
    "        correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, DTYPE), name='accuracy')\n",
    "    accuracy_summ = tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "    #summary = tf.summary.merge([loss_summ, accuracy_summ], name='summary')\n",
    "    #Alternatively, you can use tf.summary.merge_all()\n",
    "    summary = tf.summary.merge_all()\n",
    "    \n",
    "    return x, y, keep_prob_1, keep_prob_2, lr, summary, optimizer, cost, accuracy, is_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch, learn_rate_value):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    \n",
    "    Arguments:\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    session.run(optimizer, feed_dict={x:feature_batch, y:label_batch, \n",
    "                                      keep_prob_1:keep_probability[0], keep_prob_2:keep_probability[1], \n",
    "                                      lr:learn_rate_value, is_training:True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy, learn_rate_value, valid=None):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    \n",
    "    Arguments:\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    if type(valid)==tuple:\n",
    "        train_loss = session.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob_1:1.0, keep_prob_2:1.0,\n",
    "                                        lr:learn_rate_value, is_training: True})\n",
    "        train_acc = sess.run(accuracy, feed_dict={x: feature_batch, y: label_batch, keep_prob_1:1.0, keep_prob_2:1.0,\n",
    "                                              lr:learn_rate_value, is_training: True})\n",
    "        \n",
    "        val_loss = session.run(cost, feed_dict={x:valid[0], y:valid[1], keep_prob_1:1.0, keep_prob_2:1.0,\n",
    "                                        lr:learn_rate_value, is_training: False})\n",
    "        val_acc = sess.run(accuracy, feed_dict={x: valid[0], y: valid[1], keep_prob_1:1.0, keep_prob_2:1.0,\n",
    "                                              lr:learn_rate_value, is_training: False})\n",
    "        \n",
    "        print('Loss: {:>10.4f} Accuracy: {:.4f} ----- Valid Loss: {:>10.4f} Valid Accuracy: {:.4f}'\n",
    "              .format(train_loss, train_acc, val_loss, val_acc))\n",
    "    else:\n",
    "        train_loss = session.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob_1:1.0, keep_prob_2:1.0,\n",
    "                                        lr:learn_rate_value, is_training: True})\n",
    "        train_acc = sess.run(accuracy, feed_dict={x: feature_batch, y: label_batch, keep_prob_1:1.0, keep_prob_2:1.0,\n",
    "                                              lr:learn_rate_value, is_training: True})\n",
    "        \n",
    "        print('Loss: {:>10.4f} Accuracy: {:.4f}'.format(train_loss, train_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Parameters\n",
    "epochs = 12\n",
    "batch_size = 128\n",
    "keep_probability = [0.5, 0.2]\n",
    "learning_rate_init = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on a Single Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Checking the Training on a Single Batch...')\n",
    "\n",
    "x, y, keep_prob_1, keep_prob_2, lr, summary, optimizer, cost, accuracy, is_training = build_op()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training cycle\n",
    "    learning_rate = learning_rate_init\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        batch_i = 1\n",
    "        \n",
    "        for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels, learning_rate)\n",
    "        \n",
    "        print('Epoch {:>2}, Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy, learning_rate, valid=(valid_features, valid_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_model_path = './DeepTF_Model/model2'\n",
    "\n",
    "x, y, keep_prob_1, keep_prob_2, lr, summary, optimizer, cost, accuracy, is_training = build_op()\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    learning_rate = learning_rate_init\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        n_batches = 12\n",
    "        index = np.array(range(n_batches))+1\n",
    "        np.random.shuffle(index)\n",
    "        \n",
    "        for batch_i in index : # range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels, learning_rate)\n",
    "\n",
    "            print('Epoch {:>2}, Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy, learning_rate, valid=(valid_features, valid_labels))\n",
    "    \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y, keep_prob_1, keep_prob_2, lr, summary, optimizer, cost, accuracy, is_training = build_op()\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    steps = 0\n",
    "    counter = 0\n",
    "    learning_rate = learning_rate_init\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # If you want to compare training and validation, one good way to do it is to use two separate\n",
    "    # file writer to keep logs for each process but keep them in the same folder. This way, you can \n",
    "    # later view them in the same plot. \n",
    "    #train_log_string = './log/train, learning_rate={:.5f}, batch_size={}'.format(learning_rate, batch_size)\n",
    "    valid_log_string = './log/model2_dnn_valid, learning_rate={:.5f}, batch_size={}'.format(learning_rate, batch_size)\n",
    "    #train_filewriter = tf.summary.FileWriter(train_log_string, sess.graph)\n",
    "    valid_filewriter = tf.summary.FileWriter(valid_log_string, sess.graph)\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        \n",
    "        n_batches = 12\n",
    "        index = np.array(range(n_batches))+1\n",
    "        np.random.shuffle(index)\n",
    "        \n",
    "        for batch_i in index : # range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
    "                steps += batch_features.shape[0]\n",
    "                counter += batch_features.shape[0]\n",
    "                sess.run(optimizer, feed_dict={x: batch_features, y: batch_labels,\n",
    "                                               keep_prob_1:keep_probability[0], keep_prob_2:keep_probability[1],\n",
    "                                               lr:learning_rate, is_training:True})\n",
    "\n",
    "                # Log only after the model is trained on every 500 samples. Getting summary takes time, so the \n",
    "                # more frequently you look, the more extra time it'll cost you.\n",
    "                if counter > 500:\n",
    "                    #train_summ = sess.run(summary, feed_dict={x: batch_features, y: batch_labels,\n",
    "                    #                                                   keep_prob: 1., lr:learning_rate})\n",
    "                    #train_filewriter.add_summary(train_summ, steps)\n",
    "                    valid_summ = sess.run(summary, feed_dict={x: valid_features, y: valid_labels,\n",
    "                                                               keep_prob_1:1.0, keep_prob_2:1.0,\n",
    "                                                              lr:learning_rate, is_training:False})\n",
    "\n",
    "                    valid_filewriter.add_summary(valid_summ, steps)\n",
    "                    counter -= 500\n",
    "\n",
    "            print('Epoch {:>2}, Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy, learning_rate, valid=(valid_features, valid_labels))\n",
    "    # Save Model\n",
    "    save_model_path = './DeepTF_Model/model2'\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on the batches 13~15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./DeepTF_Model/model2\n",
      "Testing Accuracy: 0.9031096796194712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 32\n",
    "\n",
    "save_model_path = './DeepTF_Model/model2'\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features_1, test_labels_1 = pickle.load(open('./dataset/train_batch_13.p', mode='rb'))\n",
    "    test_features_2, test_labels_2 = pickle.load(open('./dataset/train_batch_14.p', mode='rb'))\n",
    "    test_features_3, test_labels_3 = pickle.load(open('./dataset/train_batch_15.p', mode='rb'))\n",
    "    test_features = np.concatenate([test_features_1,test_features_2,test_features_3])\n",
    "    test_labels = np.concatenate([test_labels_1, test_labels_2, test_labels_3])\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('inputs/x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('inputs/y:0')\n",
    "        loaded_keep_prob_1 = loaded_graph.get_tensor_by_name('inputs/keep_prob_1:0')\n",
    "        loaded_keep_prob_2 = loaded_graph.get_tensor_by_name('inputs/keep_prob_2:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits/logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('predictions/accuracy:0')\n",
    "        loaded_is_training = loaded_graph.get_tensor_by_name('inputs/is_training:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob_1: 1.0, loaded_keep_prob_2: 1.0,\n",
    "                           loaded_is_training:False})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "        \n",
    "        test_predictions = sess.run(\n",
    "            tf.nn.softmax(loaded_logits),\n",
    "            feed_dict={loaded_x: test_features, loaded_y: test_labels, loaded_keep_prob_1: 1.0, loaded_keep_prob_2: 1.0,\n",
    "                       loaded_is_training:False})\n",
    "    return test_labels, test_predictions\n",
    "\n",
    "y_test, y_pred = test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_decode=np.argmax(y_pred,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model with Confusion Matrix, F1-Score, ROC Curve, AUC..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "|                | Predicted Positive | Predicted Negative |\n",
    "|:--------------:|:------------------:|:------------------:|\n",
    "|Actual Positive | TP (True Positive) | FN (False Negative)|\n",
    "|Actual Negative | FP (False Positive)| TN (True Negative) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "n_classes = 2\n",
    "label_binarizer = LabelBinarizer()\n",
    "label_binarizer.fit(range(n_classes))\n",
    "y_test_decode = label_binarizer.inverse_transform(y_test)\n",
    "cnf_matrix = confusion_matrix(y_test_decode, y_pred_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[356  36]\n",
      " [ 34 282]]\n",
      "Normalized confusion matrix\n",
      "[[0.91 0.09]\n",
      " [0.11 0.89]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "class_names=np.array(['Spliced', 'Retained'])\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-Score\n",
    "$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "\n",
    "$Precision = \\frac{TP}{TP + FP}$\n",
    "\n",
    "$Recall = \\frac{TP}{TP + TN}$\n",
    "\n",
    "$F1-score =2 \\times {\\frac{2}{\\frac{1}{Recall} + \\frac{1}{Precision}}} = 2 \\times{\\frac{Precision \\times Recall}{Precision + Recall}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8998064828253507\n",
      "Recall: 0.9002841642986308\n",
      "F1 Score: 0.9000379194333061\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision,recall,f1_score,support=precision_recall_fscore_support(y_test_decode, y_pred_decode, average='macro')\n",
    "print('Precision: {}'.format(precision))\n",
    "print('Recall: {}'.format(recall))\n",
    "print('F1 Score: {}'.format(f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "#plt.plot(fpr[0], tpr[0], color='darkorange',\n",
    "#         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[0])\n",
    "colors = cycle(['aqua', 'darkorange'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_scores(score_list, mode):\n",
    "    \"\"\"\n",
    "    Print the acc and auc of cross-validation data\n",
    "    \"\"\"\n",
    "    score_array = np.asarray(score_list)\n",
    "    if mode == 'percentage':\n",
    "        score = '%.2f +- %.2f%%' % (np.mean(score_array)*100, np.std(score_array)*100)\n",
    "    elif mode == 'decimal':\n",
    "        score = '%.3f +- %.3f' % (np.mean(score_array), np.std(score_array))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=6666)\n",
    "print('%d-fold cross validation'%10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = pickle.load(open('./dataset/validation.p', mode='rb'))\n",
    "for batch_id in range(1,12+1):\n",
    "    filename = './dataset/train_batch_' + str(batch_id) + '.p'\n",
    "    features, labels = pickle.load(open(filename, mode='rb'))\n",
    "    train_features = np.vstack([train_features,features])\n",
    "    train_labels=np.vstack([train_labels,labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3078, 307, 2500)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeepTf(X, keep_prob_1, keep_prob_2, is_training=False):\n",
    "    \"\"\"\n",
    "    Create a convolutional/dense neural network model\n",
    "    \n",
    "    Arguments:\n",
    "    : x: Placeholder tensor that holds data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : is_training: Placeholder bool that hold the flag to determine training is True or False, default is False\n",
    "    \n",
    "    Returns:\n",
    "    : Tensor that represents logits\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.name_scope(\"CNN\"):\n",
    "    \n",
    "        with tf.variable_scope('conv1'):\n",
    "            X = conv1d(X, conv_num_outputs=128, conv_ksize=7, conv_strides=1, is_training=is_training, padding = 'SAME', l2_regularize=True, wd=0.001)\n",
    "            X = max_pooling1d(X, pool_ksize=3, pool_strides=1)\n",
    "            X = tf.nn.dropout(X, keep_prob_2)\n",
    "\n",
    "        X = flatten(X)\n",
    "        \n",
    "        with tf.variable_scope('fc1'):\n",
    "            X = fully_conn(X, num_outputs=128, is_training= is_training, l2_regularize=True, wd=0.001)\n",
    "            X = tf.nn.dropout(X, keep_prob_2)\n",
    "        with tf.variable_scope('fc2'):\n",
    "            X = fully_conn(X, num_outputs=256, is_training = is_training, l2_regularize=True, wd=0.001)\n",
    "            X = tf.nn.dropout(X, keep_prob_2)\n",
    "            \n",
    "        X = output(X, 2)\n",
    "        \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for the 1 th-fold...\n",
      "Epoch  1  Loss:     0.6330 Accuracy: 0.6463 ----- Valid Loss:     0.6438 Valid Accuracy: 0.7045\n",
      "Epoch  2  Loss:     0.4447 Accuracy: 0.7927 ----- Valid Loss:     0.6391 Valid Accuracy: 0.6071\n",
      "Epoch  3  Loss:     0.3409 Accuracy: 0.8659 ----- Valid Loss:     0.6213 Valid Accuracy: 0.7890\n",
      "Epoch  4  Loss:     0.2649 Accuracy: 0.8902 ----- Valid Loss:     0.6011 Valid Accuracy: 0.8279\n",
      "Epoch  5  Loss:     0.1864 Accuracy: 0.9268 ----- Valid Loss:     0.5891 Valid Accuracy: 0.6916\n",
      "Epoch  6  Loss:     0.1471 Accuracy: 0.9512 ----- Valid Loss:     0.5320 Valid Accuracy: 0.7695\n",
      "Epoch  7  Loss:     0.1159 Accuracy: 0.9268 ----- Valid Loss:     0.4982 Valid Accuracy: 0.7468\n",
      "Epoch  8  Loss:     0.0858 Accuracy: 0.9634 ----- Valid Loss:     0.4138 Valid Accuracy: 0.8312\n",
      "Epoch  9  Loss:     0.0566 Accuracy: 0.9756 ----- Valid Loss:     0.3667 Valid Accuracy: 0.8571\n",
      "Epoch 10  Loss:     0.0316 Accuracy: 1.0000 ----- Valid Loss:     0.3282 Valid Accuracy: 0.8636\n",
      "Epoch 11  Loss:     0.0316 Accuracy: 0.9878 ----- Valid Loss:     0.2916 Valid Accuracy: 0.8669\n",
      "Epoch 12  Loss:     0.0323 Accuracy: 0.9878 ----- Valid Loss:     0.2820 Valid Accuracy: 0.8766\n",
      "Training for the 2 th-fold...\n",
      "Epoch  1  Loss:     0.4772 Accuracy: 0.7439 ----- Valid Loss:     0.6577 Valid Accuracy: 0.6169\n",
      "Epoch  2  Loss:     0.3350 Accuracy: 0.8659 ----- Valid Loss:     0.6409 Valid Accuracy: 0.6429\n",
      "Epoch  3  Loss:     0.2277 Accuracy: 0.9146 ----- Valid Loss:     0.6791 Valid Accuracy: 0.4903\n",
      "Epoch  4  Loss:     0.1987 Accuracy: 0.9024 ----- Valid Loss:     0.6721 Valid Accuracy: 0.4903\n",
      "Epoch  5  Loss:     0.1383 Accuracy: 0.9268 ----- Valid Loss:     0.6125 Valid Accuracy: 0.5877\n",
      "Epoch  6  Loss:     0.0861 Accuracy: 0.9634 ----- Valid Loss:     0.5507 Valid Accuracy: 0.7110\n",
      "Epoch  7  Loss:     0.1222 Accuracy: 0.9512 ----- Valid Loss:     0.4659 Valid Accuracy: 0.8084\n",
      "Epoch  8  Loss:     0.0402 Accuracy: 0.9878 ----- Valid Loss:     0.4430 Valid Accuracy: 0.8214\n",
      "Epoch  9  Loss:     0.0193 Accuracy: 0.9878 ----- Valid Loss:     0.4000 Valid Accuracy: 0.8409\n",
      "Epoch 10  Loss:     0.0190 Accuracy: 1.0000 ----- Valid Loss:     0.3979 Valid Accuracy: 0.8409\n",
      "Epoch 11  Loss:     0.0180 Accuracy: 0.9878 ----- Valid Loss:     0.3845 Valid Accuracy: 0.8279\n",
      "Epoch 12  Loss:     0.0144 Accuracy: 1.0000 ----- Valid Loss:     0.4254 Valid Accuracy: 0.7987\n",
      "Training for the 3 th-fold...\n",
      "Epoch  1  Loss:     0.5642 Accuracy: 0.6829 ----- Valid Loss:     0.6571 Valid Accuracy: 0.6851\n",
      "Epoch  2  Loss:     0.4428 Accuracy: 0.7439 ----- Valid Loss:     0.6416 Valid Accuracy: 0.6753\n",
      "Epoch  3  Loss:     0.4169 Accuracy: 0.7805 ----- Valid Loss:     0.6288 Valid Accuracy: 0.6169\n",
      "Epoch  4  Loss:     0.2406 Accuracy: 0.9024 ----- Valid Loss:     0.6043 Valid Accuracy: 0.7825\n",
      "Epoch  5  Loss:     0.1445 Accuracy: 0.9512 ----- Valid Loss:     0.5988 Valid Accuracy: 0.6429\n",
      "Epoch  6  Loss:     0.0910 Accuracy: 0.9878 ----- Valid Loss:     0.5458 Valid Accuracy: 0.7078\n",
      "Epoch  7  Loss:     0.0542 Accuracy: 0.9878 ----- Valid Loss:     0.5044 Valid Accuracy: 0.7435\n",
      "Epoch  8  Loss:     0.0466 Accuracy: 0.9878 ----- Valid Loss:     0.4315 Valid Accuracy: 0.8214\n",
      "Epoch  9  Loss:     0.0448 Accuracy: 0.9878 ----- Valid Loss:     0.3841 Valid Accuracy: 0.8571\n",
      "Epoch 10  Loss:     0.0575 Accuracy: 0.9756 ----- Valid Loss:     0.3445 Valid Accuracy: 0.8701\n",
      "Epoch 11  Loss:     0.0723 Accuracy: 0.9756 ----- Valid Loss:     0.3114 Valid Accuracy: 0.8734\n",
      "Epoch 12  Loss:     0.0690 Accuracy: 0.9756 ----- Valid Loss:     0.3010 Valid Accuracy: 0.8766\n",
      "Training for the 4 th-fold...\n",
      "Epoch  1  Loss:     0.5581 Accuracy: 0.6951 ----- Valid Loss:     0.6586 Valid Accuracy: 0.5942\n",
      "Epoch  2  Loss:     0.4024 Accuracy: 0.8171 ----- Valid Loss:     0.6539 Valid Accuracy: 0.6071\n",
      "Epoch  3  Loss:     0.3340 Accuracy: 0.8537 ----- Valid Loss:     0.6686 Valid Accuracy: 0.5227\n",
      "Epoch  4  Loss:     0.2278 Accuracy: 0.9146 ----- Valid Loss:     0.6249 Valid Accuracy: 0.6201\n",
      "Epoch  5  Loss:     0.1672 Accuracy: 0.9512 ----- Valid Loss:     0.5653 Valid Accuracy: 0.7890\n",
      "Epoch  6  Loss:     0.1100 Accuracy: 0.9756 ----- Valid Loss:     0.5215 Valid Accuracy: 0.8117\n",
      "Epoch  7  Loss:     0.0809 Accuracy: 0.9756 ----- Valid Loss:     0.4772 Valid Accuracy: 0.7955\n",
      "Epoch  8  Loss:     0.0762 Accuracy: 0.9634 ----- Valid Loss:     0.4159 Valid Accuracy: 0.8636\n",
      "Epoch  9  Loss:     0.0528 Accuracy: 0.9756 ----- Valid Loss:     0.3709 Valid Accuracy: 0.8734\n",
      "Epoch 10  Loss:     0.0340 Accuracy: 0.9878 ----- Valid Loss:     0.3624 Valid Accuracy: 0.8377\n",
      "Epoch 11  Loss:     0.0497 Accuracy: 0.9756 ----- Valid Loss:     0.3221 Valid Accuracy: 0.8506\n",
      "Epoch 12  Loss:     0.0375 Accuracy: 0.9756 ----- Valid Loss:     0.2997 Valid Accuracy: 0.8636\n",
      "Training for the 5 th-fold...\n",
      "Epoch  1  Loss:     0.6837 Accuracy: 0.6220 ----- Valid Loss:     0.6478 Valid Accuracy: 0.6818\n",
      "Epoch  2  Loss:     0.4831 Accuracy: 0.7683 ----- Valid Loss:     0.6449 Valid Accuracy: 0.6071\n",
      "Epoch  3  Loss:     0.3470 Accuracy: 0.8659 ----- Valid Loss:     0.6388 Valid Accuracy: 0.5747\n",
      "Epoch  4  Loss:     0.2654 Accuracy: 0.9146 ----- Valid Loss:     0.6179 Valid Accuracy: 0.6948\n",
      "Epoch  5  Loss:     0.2014 Accuracy: 0.9390 ----- Valid Loss:     0.5760 Valid Accuracy: 0.8019\n",
      "Epoch  6  Loss:     0.1388 Accuracy: 0.9512 ----- Valid Loss:     0.5486 Valid Accuracy: 0.7955\n",
      "Epoch  7  Loss:     0.0850 Accuracy: 0.9756 ----- Valid Loss:     0.4903 Valid Accuracy: 0.8214\n",
      "Epoch  8  Loss:     0.0552 Accuracy: 0.9878 ----- Valid Loss:     0.4322 Valid Accuracy: 0.8539\n",
      "Epoch  9  Loss:     0.0417 Accuracy: 0.9756 ----- Valid Loss:     0.4050 Valid Accuracy: 0.8442\n",
      "Epoch 10  Loss:     0.0227 Accuracy: 0.9878 ----- Valid Loss:     0.3959 Valid Accuracy: 0.8312\n",
      "Epoch 11  Loss:     0.0043 Accuracy: 1.0000 ----- Valid Loss:     0.3256 Valid Accuracy: 0.8669\n",
      "Epoch 12  Loss:     0.0028 Accuracy: 1.0000 ----- Valid Loss:     0.3379 Valid Accuracy: 0.8701\n",
      "Training for the 6 th-fold...\n",
      "Epoch  1  Loss:     0.5480 Accuracy: 0.7195 ----- Valid Loss:     0.6534 Valid Accuracy: 0.6299\n",
      "Epoch  2  Loss:     0.4214 Accuracy: 0.7805 ----- Valid Loss:     0.6432 Valid Accuracy: 0.5974\n",
      "Epoch  3  Loss:     0.2766 Accuracy: 0.8537 ----- Valid Loss:     0.6295 Valid Accuracy: 0.7208\n",
      "Epoch  4  Loss:     0.1994 Accuracy: 0.8902 ----- Valid Loss:     0.6008 Valid Accuracy: 0.6786\n",
      "Epoch  5  Loss:     0.1599 Accuracy: 0.9390 ----- Valid Loss:     0.5574 Valid Accuracy: 0.7565\n",
      "Epoch  6  Loss:     0.1177 Accuracy: 0.9756 ----- Valid Loss:     0.5084 Valid Accuracy: 0.8344\n",
      "Epoch  7  Loss:     0.0786 Accuracy: 0.9878 ----- Valid Loss:     0.4526 Valid Accuracy: 0.8669\n",
      "Epoch  8  Loss:     0.0482 Accuracy: 0.9878 ----- Valid Loss:     0.4026 Valid Accuracy: 0.8636\n",
      "Epoch  9  Loss:     0.0384 Accuracy: 0.9878 ----- Valid Loss:     0.3616 Valid Accuracy: 0.8669\n",
      "Epoch 10  Loss:     0.0193 Accuracy: 0.9878 ----- Valid Loss:     0.3381 Valid Accuracy: 0.8539\n",
      "Epoch 11  Loss:     0.0151 Accuracy: 0.9878 ----- Valid Loss:     0.3212 Valid Accuracy: 0.8701\n",
      "Epoch 12  Loss:     0.0439 Accuracy: 0.9756 ----- Valid Loss:     0.3054 Valid Accuracy: 0.8636\n",
      "Training for the 7 th-fold...\n",
      "Epoch  1  Loss:     0.5355 Accuracy: 0.7561 ----- Valid Loss:     0.6669 Valid Accuracy: 0.5942\n",
      "Epoch  2  Loss:     0.3944 Accuracy: 0.8537 ----- Valid Loss:     0.6522 Valid Accuracy: 0.6461\n",
      "Epoch  3  Loss:     0.3472 Accuracy: 0.8537 ----- Valid Loss:     0.6491 Valid Accuracy: 0.6071\n",
      "Epoch  4  Loss:     0.2577 Accuracy: 0.9146 ----- Valid Loss:     0.6238 Valid Accuracy: 0.7792\n",
      "Epoch  5  Loss:     0.1777 Accuracy: 0.9512 ----- Valid Loss:     0.5819 Valid Accuracy: 0.7695\n",
      "Epoch  6  Loss:     0.1315 Accuracy: 0.9634 ----- Valid Loss:     0.5385 Valid Accuracy: 0.8312\n",
      "Epoch  7  Loss:     0.0928 Accuracy: 0.9756 ----- Valid Loss:     0.4961 Valid Accuracy: 0.8052\n",
      "Epoch  8  Loss:     0.0712 Accuracy: 0.9756 ----- Valid Loss:     0.4379 Valid Accuracy: 0.8539\n",
      "Epoch  9  Loss:     0.0558 Accuracy: 0.9878 ----- Valid Loss:     0.4006 Valid Accuracy: 0.8539\n",
      "Epoch 10  Loss:     0.0236 Accuracy: 0.9878 ----- Valid Loss:     0.3738 Valid Accuracy: 0.8539\n",
      "Epoch 11  Loss:     0.0098 Accuracy: 1.0000 ----- Valid Loss:     0.3520 Valid Accuracy: 0.8539\n",
      "Epoch 12  Loss:     0.0065 Accuracy: 1.0000 ----- Valid Loss:     0.3320 Valid Accuracy: 0.8636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for the 8 th-fold...\n",
      "Epoch  1  Loss:     0.6446 Accuracy: 0.6220 ----- Valid Loss:     0.6742 Valid Accuracy: 0.5455\n",
      "Epoch  2  Loss:     0.4197 Accuracy: 0.8537 ----- Valid Loss:     0.6620 Valid Accuracy: 0.5325\n",
      "Epoch  3  Loss:     0.3163 Accuracy: 0.9268 ----- Valid Loss:     0.6366 Valid Accuracy: 0.6818\n",
      "Epoch  4  Loss:     0.2344 Accuracy: 0.9024 ----- Valid Loss:     0.6103 Valid Accuracy: 0.7760\n",
      "Epoch  5  Loss:     0.1843 Accuracy: 0.9268 ----- Valid Loss:     0.5646 Valid Accuracy: 0.8377\n",
      "Epoch  6  Loss:     0.1403 Accuracy: 0.9268 ----- Valid Loss:     0.5133 Valid Accuracy: 0.8247\n",
      "Epoch  7  Loss:     0.0707 Accuracy: 0.9634 ----- Valid Loss:     0.4605 Valid Accuracy: 0.8182\n",
      "Epoch  8  Loss:     0.0548 Accuracy: 0.9878 ----- Valid Loss:     0.4144 Valid Accuracy: 0.8182\n",
      "Epoch  9  Loss:     0.0469 Accuracy: 0.9878 ----- Valid Loss:     0.3941 Valid Accuracy: 0.8182\n",
      "Epoch 10  Loss:     0.0331 Accuracy: 0.9878 ----- Valid Loss:     0.3470 Valid Accuracy: 0.8506\n",
      "Epoch 11  Loss:     0.0541 Accuracy: 0.9756 ----- Valid Loss:     0.3096 Valid Accuracy: 0.8701\n",
      "Epoch 12  Loss:     0.0365 Accuracy: 0.9878 ----- Valid Loss:     0.3100 Valid Accuracy: 0.8604\n",
      "Training for the 9 th-fold...\n",
      "Epoch  1  Loss:     0.6487 Accuracy: 0.6585 ----- Valid Loss:     0.6502 Valid Accuracy: 0.6494\n",
      "Epoch  2  Loss:     0.5118 Accuracy: 0.7439 ----- Valid Loss:     0.6473 Valid Accuracy: 0.6526\n",
      "Epoch  3  Loss:     0.4114 Accuracy: 0.8537 ----- Valid Loss:     0.6524 Valid Accuracy: 0.5877\n",
      "Epoch  4  Loss:     0.3134 Accuracy: 0.8415 ----- Valid Loss:     0.6220 Valid Accuracy: 0.6039\n",
      "Epoch  5  Loss:     0.2424 Accuracy: 0.9146 ----- Valid Loss:     0.5826 Valid Accuracy: 0.6721\n",
      "Epoch  6  Loss:     0.1607 Accuracy: 0.9512 ----- Valid Loss:     0.5170 Valid Accuracy: 0.7890\n",
      "Epoch  7  Loss:     0.1032 Accuracy: 0.9634 ----- Valid Loss:     0.4691 Valid Accuracy: 0.8312\n",
      "Epoch  8  Loss:     0.0827 Accuracy: 0.9512 ----- Valid Loss:     0.4274 Valid Accuracy: 0.8474\n",
      "Epoch  9  Loss:     0.0511 Accuracy: 0.9756 ----- Valid Loss:     0.3834 Valid Accuracy: 0.8636\n",
      "Epoch 10  Loss:     0.0364 Accuracy: 0.9878 ----- Valid Loss:     0.3400 Valid Accuracy: 0.8799\n",
      "Epoch 11  Loss:     0.0204 Accuracy: 0.9878 ----- Valid Loss:     0.3135 Valid Accuracy: 0.8831\n",
      "Epoch 12  Loss:     0.0213 Accuracy: 0.9878 ----- Valid Loss:     0.3101 Valid Accuracy: 0.8604\n",
      "Training for the 10 th-fold...\n",
      "Epoch  1  Loss:     0.5047 Accuracy: 0.7857 ----- Valid Loss:     0.6645 Valid Accuracy: 0.6601\n",
      "Epoch  2  Loss:     0.3884 Accuracy: 0.8214 ----- Valid Loss:     0.6593 Valid Accuracy: 0.6863\n",
      "Epoch  3  Loss:     0.3067 Accuracy: 0.8810 ----- Valid Loss:     0.6788 Valid Accuracy: 0.4869\n",
      "Epoch  4  Loss:     0.2164 Accuracy: 0.9405 ----- Valid Loss:     0.7164 Valid Accuracy: 0.4673\n",
      "Epoch  5  Loss:     0.1683 Accuracy: 0.9167 ----- Valid Loss:     0.6734 Valid Accuracy: 0.4902\n",
      "Epoch  6  Loss:     0.1195 Accuracy: 0.9405 ----- Valid Loss:     0.6238 Valid Accuracy: 0.5523\n",
      "Epoch  7  Loss:     0.0762 Accuracy: 0.9881 ----- Valid Loss:     0.5647 Valid Accuracy: 0.6242\n",
      "Epoch  8  Loss:     0.0500 Accuracy: 0.9762 ----- Valid Loss:     0.4663 Valid Accuracy: 0.7974\n",
      "Epoch  9  Loss:     0.0262 Accuracy: 1.0000 ----- Valid Loss:     0.4081 Valid Accuracy: 0.8268\n",
      "Epoch 10  Loss:     0.0169 Accuracy: 0.9881 ----- Valid Loss:     0.3737 Valid Accuracy: 0.8072\n",
      "Epoch 11  Loss:     0.0225 Accuracy: 0.9881 ----- Valid Loss:     0.3565 Valid Accuracy: 0.8203\n",
      "Epoch 12  Loss:     0.0049 Accuracy: 1.0000 ----- Valid Loss:     0.3711 Valid Accuracy: 0.8235\n",
      "Loss: 0.327 +- 0.040\n",
      "Accuracy: 85.57 +- 2.37%\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2\n",
    "label_binarizer = LabelBinarizer()\n",
    "label_binarizer.fit(range(n_classes))\n",
    "train_labels_decode = label_binarizer.inverse_transform(train_labels)\n",
    "crossvalidation_loss_CNN = []\n",
    "crossvalidation_acc_CNN = []\n",
    "fold=1\n",
    "for train_index, valid_index in skf.split(train_features, train_labels_decode):\n",
    "    x_train, valid_features = train_features[train_index], train_features[valid_index]\n",
    "    y_train, valid_labels = train_labels[train_index], train_labels[valid_index]\n",
    "    #print(x_train.shape)\n",
    "    #print(x_valid.shape)\n",
    "    x, y, keep_prob_1, keep_prob_2, lr, summary, optimizer, cost, accuracy, is_training = build_op()\n",
    "    print('Training for the %d th-fold...'%fold)\n",
    "    with tf.Session() as sess:\n",
    "        # Initializing the variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        learning_rate = learning_rate_init\n",
    "        for epoch in range(epochs):\n",
    "            for batch_features, batch_labels in batch_features_labels(x_train, y_train, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels, learning_rate)\n",
    "            print('Epoch {:>2}  '.format(epoch + 1), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy, learning_rate, valid=(valid_features, valid_labels))\n",
    "        val_loss = sess.run(cost, feed_dict={x: valid_features, y: valid_labels, keep_prob_1:1.0, keep_prob_2:1.0, is_training: False})\n",
    "        val_acc = sess.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob_1:1.0, keep_prob_2:1.0, is_training: False})\n",
    "    # Logs for each fold\n",
    "    crossvalidation_loss_CNN.append(val_loss)\n",
    "    crossvalidation_acc_CNN.append(val_acc)\n",
    "    fold+=1\n",
    "avg_loss_CNN = cross_validation_scores(crossvalidation_loss_CNN, 'decimal')\n",
    "avg_acc_CNN = cross_validation_scores(crossvalidation_acc_CNN, 'percentage')\n",
    "print('Loss: {}'.format(avg_loss_CNN))\n",
    "print('Accuracy: {}'.format(avg_acc_CNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeepTf(X, keep_prob_1, keep_prob_2, is_training=False):\n",
    "    \"\"\"\n",
    "    Create a convolutional/dense neural network model\n",
    "    \n",
    "    Arguments:\n",
    "    : x: Placeholder tensor that holds data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : is_training: Placeholder bool that hold the flag to determine training is True or False, default is False\n",
    "    \n",
    "    Returns:\n",
    "    : Tensor that represents logits\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.name_scope(\"DNN\"):\n",
    "        \n",
    "        X = flatten(X)\n",
    "        \n",
    "        with tf.variable_scope('fc1'):\n",
    "            X = fully_conn(X, num_outputs=128, is_training= is_training, l2_regularize=True, wd=0.01)\n",
    "            X = tf.nn.dropout(X, keep_prob_1)\n",
    "        with tf.variable_scope('fc2'):\n",
    "            X = fully_conn(X, num_outputs=256, is_training = is_training, l2_regularize=True, wd=0.01)\n",
    "            X = tf.nn.dropout(X, keep_prob_1)\n",
    "        with tf.variable_scope('fc3'):\n",
    "            X = fully_conn(X, num_outputs=512, is_training = is_training, l2_regularize=True, wd=0.01)\n",
    "            X = tf.nn.dropout(X, keep_prob_2)\n",
    "        with tf.variable_scope('fc4'):\n",
    "            X = fully_conn(X, num_outputs=1024, is_training = is_training, l2_regularize=True, wd=0.01)\n",
    "            X = tf.nn.dropout(X, keep_prob_2)\n",
    "            \n",
    "        X = output(X, 2)\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for the 1 th-fold...\n",
      "Epoch  1  Loss:     0.5003 Accuracy: 0.8293 ----- Valid Loss:     0.4741 Valid Accuracy: 0.7922\n",
      "Epoch  2  Loss:     0.2033 Accuracy: 0.9512 ----- Valid Loss:     0.3405 Valid Accuracy: 0.9058\n",
      "Epoch  3  Loss:     0.0405 Accuracy: 0.9756 ----- Valid Loss:     0.3681 Valid Accuracy: 0.9123\n",
      "Epoch  4  Loss:     0.0347 Accuracy: 0.9756 ----- Valid Loss:     0.4573 Valid Accuracy: 0.8961\n",
      "Epoch  5  Loss:     0.0008 Accuracy: 1.0000 ----- Valid Loss:     0.5329 Valid Accuracy: 0.8831\n",
      "Epoch  6  Loss:     0.0011 Accuracy: 1.0000 ----- Valid Loss:     0.3701 Valid Accuracy: 0.9058\n",
      "Epoch  7  Loss:     0.0280 Accuracy: 0.9878 ----- Valid Loss:     0.3557 Valid Accuracy: 0.9156\n",
      "Epoch  8  Loss:     0.1812 Accuracy: 0.9634 ----- Valid Loss:     0.3556 Valid Accuracy: 0.9058\n",
      "Epoch  9  Loss:     0.0286 Accuracy: 0.9878 ----- Valid Loss:     0.3861 Valid Accuracy: 0.8961\n",
      "Epoch 10  Loss:     0.0793 Accuracy: 0.9756 ----- Valid Loss:     0.3705 Valid Accuracy: 0.8961\n",
      "Epoch 11  Loss:     0.0053 Accuracy: 1.0000 ----- Valid Loss:     0.3967 Valid Accuracy: 0.8994\n",
      "Epoch 12  Loss:     0.0605 Accuracy: 0.9878 ----- Valid Loss:     0.2723 Valid Accuracy: 0.8994\n",
      "Training for the 2 th-fold...\n",
      "Epoch  1  Loss:     0.5410 Accuracy: 0.7561 ----- Valid Loss:     0.4923 Valid Accuracy: 0.7825\n",
      "Epoch  2  Loss:     0.2718 Accuracy: 0.9390 ----- Valid Loss:     0.4838 Valid Accuracy: 0.8214\n",
      "Epoch  3  Loss:     0.1280 Accuracy: 0.9634 ----- Valid Loss:     0.6834 Valid Accuracy: 0.8701\n",
      "Epoch  4  Loss:     0.2695 Accuracy: 0.9878 ----- Valid Loss:     0.6171 Valid Accuracy: 0.8701\n",
      "Epoch  5  Loss:     0.0339 Accuracy: 0.9878 ----- Valid Loss:     0.6624 Valid Accuracy: 0.8636\n",
      "Epoch  6  Loss:     0.0029 Accuracy: 1.0000 ----- Valid Loss:     0.5285 Valid Accuracy: 0.8864\n",
      "Epoch  7  Loss:     0.0061 Accuracy: 1.0000 ----- Valid Loss:     0.6086 Valid Accuracy: 0.8539\n",
      "Epoch  8  Loss:     0.1737 Accuracy: 0.9756 ----- Valid Loss:     0.5512 Valid Accuracy: 0.8442\n",
      "Epoch  9  Loss:     0.0002 Accuracy: 1.0000 ----- Valid Loss:     0.5354 Valid Accuracy: 0.8604\n",
      "Epoch 10  Loss:     0.0435 Accuracy: 0.9756 ----- Valid Loss:     0.4886 Valid Accuracy: 0.8604\n",
      "Epoch 11  Loss:     0.0085 Accuracy: 1.0000 ----- Valid Loss:     0.5197 Valid Accuracy: 0.8442\n",
      "Epoch 12  Loss:     0.0005 Accuracy: 1.0000 ----- Valid Loss:     0.4206 Valid Accuracy: 0.8734\n",
      "Training for the 3 th-fold...\n",
      "Epoch  1  Loss:     0.4851 Accuracy: 0.8171 ----- Valid Loss:     0.4575 Valid Accuracy: 0.7825\n",
      "Epoch  2  Loss:     0.2459 Accuracy: 0.9512 ----- Valid Loss:     0.4062 Valid Accuracy: 0.8734\n",
      "Epoch  3  Loss:     0.1702 Accuracy: 0.9878 ----- Valid Loss:     0.3720 Valid Accuracy: 0.8831\n",
      "Epoch  4  Loss:     0.0458 Accuracy: 0.9878 ----- Valid Loss:     0.4236 Valid Accuracy: 0.8799\n",
      "Epoch  5  Loss:     0.0329 Accuracy: 0.9878 ----- Valid Loss:     0.3560 Valid Accuracy: 0.8766\n",
      "Epoch  6  Loss:     0.1012 Accuracy: 0.9756 ----- Valid Loss:     0.3891 Valid Accuracy: 0.8766\n",
      "Epoch  7  Loss:     0.1209 Accuracy: 0.9756 ----- Valid Loss:     0.4457 Valid Accuracy: 0.8669\n",
      "Epoch  8  Loss:     0.1081 Accuracy: 0.9756 ----- Valid Loss:     0.4490 Valid Accuracy: 0.8604\n",
      "Epoch  9  Loss:     0.0052 Accuracy: 1.0000 ----- Valid Loss:     0.3870 Valid Accuracy: 0.8864\n",
      "Epoch 10  Loss:     0.0104 Accuracy: 0.9878 ----- Valid Loss:     0.3175 Valid Accuracy: 0.8864\n",
      "Epoch 11  Loss:     0.1083 Accuracy: 0.9878 ----- Valid Loss:     0.3021 Valid Accuracy: 0.8799\n",
      "Epoch 12  Loss:     0.0127 Accuracy: 1.0000 ----- Valid Loss:     0.3135 Valid Accuracy: 0.8799\n",
      "Training for the 4 th-fold...\n",
      "Epoch  1  Loss:     0.5202 Accuracy: 0.7683 ----- Valid Loss:     0.5159 Valid Accuracy: 0.7792\n",
      "Epoch  2  Loss:     0.1542 Accuracy: 0.9390 ----- Valid Loss:     0.3653 Valid Accuracy: 0.8799\n",
      "Epoch  3  Loss:     0.0159 Accuracy: 0.9878 ----- Valid Loss:     0.3762 Valid Accuracy: 0.9026\n",
      "Epoch  4  Loss:     0.1095 Accuracy: 0.9878 ----- Valid Loss:     0.4450 Valid Accuracy: 0.8766\n",
      "Epoch  5  Loss:     0.0778 Accuracy: 0.9878 ----- Valid Loss:     0.3919 Valid Accuracy: 0.8799\n",
      "Epoch  6  Loss:     0.0093 Accuracy: 1.0000 ----- Valid Loss:     0.3853 Valid Accuracy: 0.8961\n",
      "Epoch  7  Loss:     0.0328 Accuracy: 0.9878 ----- Valid Loss:     0.3232 Valid Accuracy: 0.9058\n",
      "Epoch  8  Loss:     0.0018 Accuracy: 1.0000 ----- Valid Loss:     0.3123 Valid Accuracy: 0.9058\n",
      "Epoch  9  Loss:     0.0004 Accuracy: 1.0000 ----- Valid Loss:     0.3731 Valid Accuracy: 0.8896\n",
      "Epoch 10  Loss:     0.1374 Accuracy: 0.9756 ----- Valid Loss:     0.3693 Valid Accuracy: 0.8799\n",
      "Epoch 11  Loss:     0.0011 Accuracy: 1.0000 ----- Valid Loss:     0.3696 Valid Accuracy: 0.8961\n",
      "Epoch 12  Loss:     0.0326 Accuracy: 0.9756 ----- Valid Loss:     0.2938 Valid Accuracy: 0.9091\n",
      "Training for the 5 th-fold...\n",
      "Epoch  1  Loss:     0.6253 Accuracy: 0.7683 ----- Valid Loss:     0.4840 Valid Accuracy: 0.7695\n",
      "Epoch  2  Loss:     0.2237 Accuracy: 0.9512 ----- Valid Loss:     0.4341 Valid Accuracy: 0.8669\n",
      "Epoch  3  Loss:     0.1161 Accuracy: 0.9756 ----- Valid Loss:     0.4269 Valid Accuracy: 0.9026\n",
      "Epoch  4  Loss:     0.0005 Accuracy: 1.0000 ----- Valid Loss:     0.5417 Valid Accuracy: 0.9026\n",
      "Epoch  5  Loss:     0.1690 Accuracy: 0.9756 ----- Valid Loss:     0.5279 Valid Accuracy: 0.9091\n",
      "Epoch  6  Loss:     0.0202 Accuracy: 0.9878 ----- Valid Loss:     0.4165 Valid Accuracy: 0.8896\n",
      "Epoch  7  Loss:     0.1458 Accuracy: 0.9756 ----- Valid Loss:     0.4688 Valid Accuracy: 0.8799\n",
      "Epoch  8  Loss:     0.1550 Accuracy: 0.9756 ----- Valid Loss:     0.4229 Valid Accuracy: 0.8994\n",
      "Epoch  9  Loss:     0.0049 Accuracy: 1.0000 ----- Valid Loss:     0.4005 Valid Accuracy: 0.8994\n",
      "Epoch 10  Loss:     0.0192 Accuracy: 0.9878 ----- Valid Loss:     0.3957 Valid Accuracy: 0.8994\n",
      "Epoch 11  Loss:     0.0596 Accuracy: 0.9878 ----- Valid Loss:     0.4142 Valid Accuracy: 0.8701\n",
      "Epoch 12  Loss:     0.0202 Accuracy: 0.9878 ----- Valid Loss:     0.3740 Valid Accuracy: 0.8896\n",
      "Training for the 6 th-fold...\n",
      "Epoch  1  Loss:     0.4832 Accuracy: 0.7683 ----- Valid Loss:     0.4733 Valid Accuracy: 0.8084\n",
      "Epoch  2  Loss:     0.2943 Accuracy: 0.9268 ----- Valid Loss:     0.3151 Valid Accuracy: 0.8896\n",
      "Epoch  3  Loss:     0.0814 Accuracy: 0.9756 ----- Valid Loss:     0.4271 Valid Accuracy: 0.8961\n",
      "Epoch  4  Loss:     0.0033 Accuracy: 1.0000 ----- Valid Loss:     0.4679 Valid Accuracy: 0.9026\n",
      "Epoch  5  Loss:     0.0147 Accuracy: 0.9878 ----- Valid Loss:     0.5120 Valid Accuracy: 0.8896\n",
      "Epoch  6  Loss:     0.0049 Accuracy: 1.0000 ----- Valid Loss:     0.5002 Valid Accuracy: 0.8799\n",
      "Epoch  7  Loss:     0.0024 Accuracy: 1.0000 ----- Valid Loss:     0.5712 Valid Accuracy: 0.8474\n",
      "Epoch  8  Loss:     0.1725 Accuracy: 0.9756 ----- Valid Loss:     0.4758 Valid Accuracy: 0.8604\n",
      "Epoch  9  Loss:     0.1084 Accuracy: 0.9756 ----- Valid Loss:     0.4090 Valid Accuracy: 0.8864\n",
      "Epoch 10  Loss:     0.0001 Accuracy: 1.0000 ----- Valid Loss:     0.4575 Valid Accuracy: 0.8604\n",
      "Epoch 11  Loss:     0.0466 Accuracy: 0.9878 ----- Valid Loss:     0.3725 Valid Accuracy: 0.8669\n",
      "Epoch 12  Loss:     0.0783 Accuracy: 0.9756 ----- Valid Loss:     0.3670 Valid Accuracy: 0.8766\n",
      "Training for the 7 th-fold...\n",
      "Epoch  1  Loss:     0.5988 Accuracy: 0.7439 ----- Valid Loss:     0.5214 Valid Accuracy: 0.7532\n",
      "Epoch  2  Loss:     0.2505 Accuracy: 0.9146 ----- Valid Loss:     0.4483 Valid Accuracy: 0.8377\n",
      "Epoch  3  Loss:     0.0360 Accuracy: 0.9878 ----- Valid Loss:     0.6552 Valid Accuracy: 0.8766\n",
      "Epoch  4  Loss:     0.0244 Accuracy: 0.9878 ----- Valid Loss:     0.6285 Valid Accuracy: 0.8929\n",
      "Epoch  5  Loss:     0.1386 Accuracy: 0.9634 ----- Valid Loss:     0.5313 Valid Accuracy: 0.8831\n",
      "Epoch  6  Loss:     0.0067 Accuracy: 1.0000 ----- Valid Loss:     0.5947 Valid Accuracy: 0.8701\n",
      "Epoch  7  Loss:     0.1734 Accuracy: 0.9756 ----- Valid Loss:     0.5170 Valid Accuracy: 0.8442\n",
      "Epoch  8  Loss:     0.0033 Accuracy: 1.0000 ----- Valid Loss:     0.4758 Valid Accuracy: 0.8636\n",
      "Epoch  9  Loss:     0.1503 Accuracy: 0.9756 ----- Valid Loss:     0.5470 Valid Accuracy: 0.8506\n",
      "Epoch 10  Loss:     0.0019 Accuracy: 1.0000 ----- Valid Loss:     0.4557 Valid Accuracy: 0.8831\n",
      "Epoch 11  Loss:     0.0486 Accuracy: 0.9878 ----- Valid Loss:     0.3944 Valid Accuracy: 0.8734\n",
      "Epoch 12  Loss:     0.0382 Accuracy: 0.9878 ----- Valid Loss:     0.4538 Valid Accuracy: 0.8766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for the 8 th-fold...\n",
      "Epoch  1  Loss:     0.8066 Accuracy: 0.7561 ----- Valid Loss:     0.6632 Valid Accuracy: 0.6688\n",
      "Epoch  2  Loss:     0.3060 Accuracy: 0.9390 ----- Valid Loss:     0.4152 Valid Accuracy: 0.8701\n",
      "Epoch  3  Loss:     0.1221 Accuracy: 0.9634 ----- Valid Loss:     0.6397 Valid Accuracy: 0.8669\n",
      "Epoch  4  Loss:     0.0070 Accuracy: 1.0000 ----- Valid Loss:     0.7144 Valid Accuracy: 0.8994\n",
      "Epoch  5  Loss:     0.1369 Accuracy: 0.9878 ----- Valid Loss:     0.5732 Valid Accuracy: 0.8896\n",
      "Epoch  6  Loss:     0.1057 Accuracy: 0.9878 ----- Valid Loss:     0.5657 Valid Accuracy: 0.8961\n",
      "Epoch  7  Loss:     0.0706 Accuracy: 0.9878 ----- Valid Loss:     0.4497 Valid Accuracy: 0.8896\n",
      "Epoch  8  Loss:     0.0986 Accuracy: 0.9878 ----- Valid Loss:     0.4459 Valid Accuracy: 0.8701\n",
      "Epoch  9  Loss:     0.0804 Accuracy: 0.9878 ----- Valid Loss:     0.4691 Valid Accuracy: 0.8929\n",
      "Epoch 10  Loss:     0.0079 Accuracy: 1.0000 ----- Valid Loss:     0.4140 Valid Accuracy: 0.8864\n",
      "Epoch 11  Loss:     0.0882 Accuracy: 0.9756 ----- Valid Loss:     0.4923 Valid Accuracy: 0.8571\n",
      "Epoch 12  Loss:     0.0206 Accuracy: 0.9756 ----- Valid Loss:     0.5186 Valid Accuracy: 0.8539\n",
      "Training for the 9 th-fold...\n",
      "Epoch  1  Loss:     0.4601 Accuracy: 0.8049 ----- Valid Loss:     0.4265 Valid Accuracy: 0.8052\n",
      "Epoch  2  Loss:     0.1441 Accuracy: 0.9512 ----- Valid Loss:     0.3549 Valid Accuracy: 0.8961\n",
      "Epoch  3  Loss:     0.0553 Accuracy: 0.9756 ----- Valid Loss:     0.5080 Valid Accuracy: 0.8864\n",
      "Epoch  4  Loss:     0.0002 Accuracy: 1.0000 ----- Valid Loss:     0.5372 Valid Accuracy: 0.8864\n",
      "Epoch  5  Loss:     0.0493 Accuracy: 0.9878 ----- Valid Loss:     0.4592 Valid Accuracy: 0.8929\n",
      "Epoch  6  Loss:     0.0397 Accuracy: 0.9878 ----- Valid Loss:     0.6275 Valid Accuracy: 0.8766\n",
      "Epoch  7  Loss:     0.0034 Accuracy: 1.0000 ----- Valid Loss:     0.5604 Valid Accuracy: 0.8799\n",
      "Epoch  8  Loss:     0.0245 Accuracy: 0.9878 ----- Valid Loss:     0.3976 Valid Accuracy: 0.8961\n",
      "Epoch  9  Loss:     0.0050 Accuracy: 1.0000 ----- Valid Loss:     0.4242 Valid Accuracy: 0.8961\n",
      "Epoch 10  Loss:     0.0006 Accuracy: 1.0000 ----- Valid Loss:     0.4051 Valid Accuracy: 0.8896\n",
      "Epoch 11  Loss:     0.0422 Accuracy: 0.9878 ----- Valid Loss:     0.4047 Valid Accuracy: 0.8799\n",
      "Epoch 12  Loss:     0.0073 Accuracy: 1.0000 ----- Valid Loss:     0.3929 Valid Accuracy: 0.8994\n",
      "Training for the 10 th-fold...\n",
      "Epoch  1  Loss:     0.6462 Accuracy: 0.7857 ----- Valid Loss:     0.5427 Valid Accuracy: 0.7386\n",
      "Epoch  2  Loss:     0.2967 Accuracy: 0.9167 ----- Valid Loss:     0.3769 Valid Accuracy: 0.8431\n",
      "Epoch  3  Loss:     0.1155 Accuracy: 0.9762 ----- Valid Loss:     0.4012 Valid Accuracy: 0.8791\n",
      "Epoch  4  Loss:     0.0051 Accuracy: 1.0000 ----- Valid Loss:     0.4519 Valid Accuracy: 0.8856\n",
      "Epoch  5  Loss:     0.1562 Accuracy: 0.9762 ----- Valid Loss:     0.4620 Valid Accuracy: 0.8660\n",
      "Epoch  6  Loss:     0.0225 Accuracy: 0.9881 ----- Valid Loss:     0.4504 Valid Accuracy: 0.8824\n",
      "Epoch  7  Loss:     0.0008 Accuracy: 1.0000 ----- Valid Loss:     0.4646 Valid Accuracy: 0.8725\n",
      "Epoch  8  Loss:     0.1768 Accuracy: 0.9643 ----- Valid Loss:     0.4197 Valid Accuracy: 0.8529\n",
      "Epoch  9  Loss:     0.0721 Accuracy: 0.9762 ----- Valid Loss:     0.4642 Valid Accuracy: 0.8562\n",
      "Epoch 10  Loss:     0.0278 Accuracy: 0.9881 ----- Valid Loss:     0.4433 Valid Accuracy: 0.8758\n",
      "Epoch 11  Loss:     0.0268 Accuracy: 0.9881 ----- Valid Loss:     0.4243 Valid Accuracy: 0.8725\n",
      "Epoch 12  Loss:     0.0006 Accuracy: 1.0000 ----- Valid Loss:     0.4561 Valid Accuracy: 0.8791\n",
      "Loss: 0.386 +- 0.075\n",
      "Accuracy: 88.37 +- 1.52%\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2\n",
    "label_binarizer = LabelBinarizer()\n",
    "label_binarizer.fit(range(n_classes))\n",
    "train_labels_decode = label_binarizer.inverse_transform(train_labels)\n",
    "crossvalidation_loss_DNN = []\n",
    "crossvalidation_acc_DNN = []\n",
    "fold=1\n",
    "for train_index, valid_index in skf.split(train_features, train_labels_decode):\n",
    "    x_train, valid_features = train_features[train_index], train_features[valid_index]\n",
    "    y_train, valid_labels = train_labels[train_index], train_labels[valid_index]\n",
    "    #print(x_train.shape)\n",
    "    #print(x_valid.shape)\n",
    "    x, y, keep_prob_1, keep_prob_2, lr, summary, optimizer, cost, accuracy, is_training = build_op()\n",
    "    print('Training for the %d th-fold...'%fold)\n",
    "    with tf.Session() as sess:\n",
    "        # Initializing the variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        learning_rate = learning_rate_init\n",
    "        for epoch in range(epochs):\n",
    "            for batch_features, batch_labels in batch_features_labels(x_train, y_train, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels, learning_rate)\n",
    "            print('Epoch {:>2}  '.format(epoch + 1), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy, learning_rate, valid=(valid_features, valid_labels))\n",
    "        val_loss = sess.run(cost, feed_dict={x: valid_features, y: valid_labels, keep_prob_1:1.0, keep_prob_2:1.0, is_training: False})\n",
    "        val_acc = sess.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob_1:1.0, keep_prob_2:1.0, is_training: False})\n",
    "    # Logs for each fold\n",
    "    crossvalidation_loss_DNN.append(val_loss)\n",
    "    crossvalidation_acc_DNN.append(val_acc)\n",
    "    fold+=1\n",
    "avg_loss_DNN = cross_validation_scores(crossvalidation_loss_DNN, 'decimal')\n",
    "avg_acc_DNN = cross_validation_scores(crossvalidation_acc_DNN, 'percentage')\n",
    "print('Loss: {}'.format(avg_loss_DNN))\n",
    "print('Accuracy: {}'.format(avg_acc_DNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.327 +- 0.040\n",
      "Accuracy: 85.57 +- 2.37%\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {}'.format(avg_loss_CNN))\n",
    "print('Accuracy: {}'.format(avg_acc_CNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.386 +- 0.075\n",
      "Accuracy: 88.37 +- 1.52%\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {}'.format(avg_loss_DNN))\n",
    "print('Accuracy: {}'.format(avg_acc_DNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "30561acb99b54e3296e4b16eb48746c6": {
     "views": []
    },
    "54eb681e67dd41dfbab25d09702ae477": {
     "views": []
    },
    "7893e80c3f734d62920e54a0ceb47f69": {
     "views": []
    },
    "7dcb6b80d2db45f485d1e50743d491d0": {
     "views": []
    },
    "80f6c276e6d546e798b2da769650609a": {
     "views": []
    },
    "85ae1b2ee7044508a4c1e3106b06df37": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "a7caabbf1ea14fa28076d7369c4b0746": {
     "views": []
    },
    "d74f4a5424384e5a85be8b42baed70bd": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
